{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novel Summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kksaikrishna/anaconda3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "import nltk\n",
    "import sys\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "import search_google.api\n",
    "import urllib.request as requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path Conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_data_index = '../data/harry_potter/index.csv'\n",
    "path_book_nlp_out = '../../dependencies/book_nlp_output/'\n",
    "path_bing_neg_score = '../dependencies/bing_sentiment_lexicons/negative-words-labelled.xlsx'\n",
    "path_output_ch = '../output/top_close_characters.xlsx'\n",
    "path_output_int = '../output/character_integrity.xlsx'\n",
    "path_output_ch_rel = '../output/character_relationship.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "nltk_senti_analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Config Params DO NOT CHANGE\n",
    "cur_story_index = 6 # 10 for pp, 6 for hp\n",
    "n_close_chars = 3 \n",
    "n_top_chars = 10\n",
    "keep_pos = ['JJ','JJS','JJR','RR','RBR','RBS','VB','VBD','VBG','VBN','VBP','VBZ']\n",
    "window = 0\n",
    "n_query_max_page = 5\n",
    "n_query_per_page = 10\n",
    "concord_left_margin = 5\n",
    "concord_right_margin = 5\n",
    "n_concord = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buildargs = {\n",
    "  'serviceName': 'customsearch',\n",
    "  'version': 'v1',\n",
    "  'developerKey': 'AIzaSyBAEWHb_bLgqpmY_NY50ykZDz9JI_ZH1GQ'\n",
    "}\n",
    "\n",
    "cseargs = {\n",
    "  'q': '',\n",
    "  'cx': '009620542372427651480:rc6g5pqmltw',\n",
    "  'num': n_query_per_page,\n",
    "  'start':1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readJsonFile(jsonPath):\n",
    "    with open(jsonPath) as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeKeysFromDict(dict_vals,keepList):\n",
    "    dict_ret = {}\n",
    "    for k in keepList:\n",
    "        if(k in dict_vals):\n",
    "            dict_ret[k] = dict_vals[k]\n",
    "    return dict_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isObject(word):\n",
    "    wn_word = word.lower() + '.n.01'\n",
    "    try:\n",
    "        wn_lemma = wn.synset(wn_word)\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    l_hyper = str(list(wn_lemma.closure(lambda s: s.hypernyms())))\n",
    "    if('object.n.01' in l_hyper and 'living_thing.n.01' not in l_hyper):\n",
    "        return True\n",
    "    else:\n",
    "        return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getWordnetPos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def queryLink(url):\n",
    "    try:\n",
    "        html = requests.urlopen(url).read().decode('utf8')\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "    return nltk.word_tokenize(BeautifulSoup(html,'lxml').get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatizeWord(word,pos_tag):\n",
    "    pos_tag = getWordnetPos(pos_tag)\n",
    "    if(pos_tag != ''):\n",
    "        return lemmatizer.lemmatize(word,pos_tag)\n",
    "    else:\n",
    "        return lemmatizer.lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getConcordance(target_word, main_text, left_margin = concord_left_margin,\\\n",
    "                   right_margin = concord_right_margin,\\\n",
    "                   n_concord = n_concord,is_pre_process=True):     \n",
    "    if(n_concord == -1):\n",
    "        n_concord = np.inf\n",
    "\n",
    "    concord_text = []\n",
    "    cur_iter = 0\n",
    "    while(cur_iter < n_concord):\n",
    "        if(target_word in main_text):\n",
    "            index = main_text.index(target_word)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        concord_text += main_text[index - left_margin : index + right_margin + 1]\n",
    "\n",
    "        if(index+1 < len(main_text)):\n",
    "            main_text = main_text[index+1:]\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        cur_iter += 1\n",
    "    if(is_pre_process):\n",
    "        concord_text = preProcessConcordText(concord_text)\n",
    "    return concord_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getUnqColVals(df,col_name):\n",
    "    return list(set(df[col_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retMatchAccuracy(list1,list2,div_by_2=True):\n",
    "    n = len(set(list1).intersection(set(list2)))\n",
    "    if(div_by_2):\n",
    "        return n/len(list2)\n",
    "    return n/list(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retMatchAccuracyForTuple(list1,list2):\n",
    "    if(len(list1) != len(list2)):\n",
    "        return 0\n",
    "    \n",
    "    if(len(list1) == 0):\n",
    "        return 0\n",
    "    \n",
    "    n = len(list1)\n",
    "    acc = 0\n",
    "    hit_count = 0\n",
    "    for tup1,tup2 in zip(list1,list2):\n",
    "        if(len(tup1) != len(tup2)):\n",
    "            return 0\n",
    "        \n",
    "        acc += len(set(tup1).intersection(set(tup2)))/len(tup1)\n",
    "        hit_count += len(set(tup1).intersection(set(tup2)))\n",
    "        \n",
    "    return acc/n,hit_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exactListMatch(list1,list2):\n",
    "    if(len(list1) != len(list2)):\n",
    "        return 0\n",
    "    \n",
    "    if(len(list1) == 0):\n",
    "        return 0\n",
    "    \n",
    "    acc = len([i for i, j in zip(list1, list2) if i == j])\n",
    "    \n",
    "    return acc/len(list1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initializeCharacterMatrix(df):\n",
    "    character_distance_matrix = np.empty((len(df), len(df)))\n",
    "    character_distance_matrix[:] = np.inf\n",
    "    return character_distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createBookNLPCommand(path,story_id,isForce,isReturnPath=False):\n",
    "    jsonPath = path_book_nlp_out + story_id\n",
    "    tokensPath = path_book_nlp_out + story_id + '.tokens'\n",
    "    \n",
    "    command = './runjava novels/BookNLP -doc ../'\n",
    "    command += path\n",
    "    command += ' -p '\n",
    "    command += jsonPath\n",
    "    command += ' -tok '\n",
    "    command += tokensPath\n",
    "    if(isForce):\n",
    "        command += ' -f'\n",
    "    \n",
    "    if(isReturnPath):\n",
    "        return command, jsonPath +'/book.id.book', tokensPath\n",
    "    else:\n",
    "        return command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBookNLPTokens(path,story_id,isForce=False):\n",
    "    command,jsonPath,tokensPath = createBookNLPCommand(path,story_id,isForce,True)\n",
    "    p = subprocess.Popen(command, shell=True, cwd='../resources/book-nlp-master')\n",
    "    retval = p.wait()\n",
    "    return jsonPath[3:],tokensPath[3:],retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCharacterIDFromIndex(indices,df,lookup_col):\n",
    "    ret = []\n",
    "    for i in indices:\n",
    "        ret.append(df[lookup_col][i])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCharacterDF(df,n_top_chars=None):\n",
    "    df = df.loc[df.characterId != -1]\n",
    "    df_ch = df.groupby('characterId')['tokenId'].apply(list).reset_index(name='tokens')\n",
    "    df_ch.tokens = df_ch.tokens.apply(sorted)\n",
    "    df_ch['tok_len'] = df_ch.tokens.apply(len)\n",
    "    \n",
    "    if(n_top_chars is not None):\n",
    "        df_ch = df_ch.sort_values(by='tok_len',ascending=False).reset_index(drop=True)[:n_top_chars]\n",
    "        df_ch = df_ch.sort_values(by='tok_len').reset_index(drop=True)\n",
    "    else:\n",
    "        df_ch = df_ch.sort_values(by='tok_len',ascending=False).reset_index(drop=True)\n",
    "        \n",
    "    return df_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCharacterDistanceMatrix(df_ch):\n",
    "    character_distance_matrix = initializeCharacterMatrix(df_ch)\n",
    "\n",
    "    for index1,token1 in enumerate(df_ch.tokens):\n",
    "        for index2,token2 in enumerate(df_ch.tokens):\n",
    "            if(index1 == index2):\n",
    "                continue\n",
    "            elif(index1 < index2):\n",
    "                iter_token = token1\n",
    "                cons_token = token2\n",
    "            else:\n",
    "                iter_token = token2\n",
    "                cons_token = token1\n",
    "\n",
    "            dist = 0\n",
    "            for tok in iter_token:\n",
    "                dist += np.min(abs(np.array(cons_token)-tok))\n",
    "            character_distance_matrix[index1][index2] = (dist/(len(iter_token)))\n",
    "            \n",
    "    return character_distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNNPCount(json_data,character_id):\n",
    "    characters = json_data['characters']\n",
    "    for ch in characters:\n",
    "        if(ch['id'] == character_id):\n",
    "            if('NNPcount' in ch):\n",
    "                return ch['NNPcount']\n",
    "            else:\n",
    "                return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTopNCharacters(json_data,list_character_id,n):\n",
    "    dict_nnp_count = {}\n",
    "    for ch in list_character_id:\n",
    "        dict_nnp_count[ch] = getNNPCount(json_data,ch)\n",
    "    return sorted(list_character_id, key=dict_nnp_count.get)[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTopNCloseCharacters(df,df_ch,json_book_data,character_distance_matrix,n_top_chars=10,n_close_chars=3):\n",
    "    closest_characters = {}\n",
    "    for index,character_distance_vector in enumerate(character_distance_matrix):\n",
    "        min_distance_characters = getCharacterIDFromIndex(np.argsort(character_distance_vector)[:n_close_chars],\\\n",
    "                                                          df_ch,'characterId')\n",
    "        i_ch = getCharacterIDFromIndex([index],df_ch,'characterId')\n",
    "        closest_characters[i_ch[0]] = min_distance_characters\n",
    "        \n",
    "    list_character_id = set(df.characterId)\n",
    "    list_character_id.remove(-1)\n",
    "    list_character_id = list(list_character_id)\n",
    "    \n",
    "    top_n_ch = getTopNCharacters(json_book_data,list_character_id,n_top_chars)\n",
    "    \n",
    "    return removeKeysFromDict(closest_characters,top_n_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def returnIDNameDict(json_data):\n",
    "    dict_char = {}\n",
    "    characters = json_data['characters']\n",
    "    for ch in characters:\n",
    "        dict_char[ch['id']] = ch['names'][0]['n']\n",
    "    return dict_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transformDictIDToName(dict_characters,dict_id_char,isOnlyKey=True):\n",
    "    dict_ret = {}\n",
    "    for key,val in dict_characters.items():\n",
    "        if(isOnlyKey):\n",
    "            dict_ret[dict_id_char[key]]  = val\n",
    "        else:\n",
    "            cur = []\n",
    "            for ch in val:\n",
    "                 cur.append(dict_id_char[ch])\n",
    "            dict_ret[dict_id_char[key]] = cur\n",
    "            \n",
    "    return dict_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getEquivalentSentId(df,list_token_id):\n",
    "    sentId = set()\n",
    "    for token_id in list_token_id:\n",
    "        sentId.add(df.loc[df.tokenId == token_id].sentenceID.reset_index(drop=True)[0])\n",
    "    return list(sentId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSentTextById(df,list_sent_id,window=0,keep_pos=None,is_remove_stop_words=True,is_lemmatize=True,isStr = False):\n",
    "    window_sent_id = []\n",
    "    for sent_id in list_sent_id:\n",
    "        window_sent_id += list(range(sent_id-window,sent_id+window+1))\n",
    "        \n",
    "    df_sent_window = df.loc[df.sentenceID.isin(window_sent_id)]\n",
    "    \n",
    "    if(keep_pos is not None and len(df_sent_window) != 0):\n",
    "        df_sent_window = df_sent_window.loc[df_sent_window.pos.isin(keep_pos)]\n",
    "    \n",
    "    if(is_remove_stop_words and len(df_sent_window) != 0):\n",
    "        df_sent_window = df_sent_window.loc[~df_sent_window.lemma.isin(stop_words)]\n",
    "        \n",
    "    if(is_lemmatize and len(df_sent_window) != 0):\n",
    "        df_sent_window.lemma = df_sent_window.apply(lambda row: lemmatizeWord(row['lemma'], row['pos']), axis=1)\n",
    "    \n",
    "    if(isStr):\n",
    "        return ' '.join(list(df_sent_window.lemma))\n",
    "    \n",
    "    return list(df_sent_window.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSpeechText(json_data,character_id,window,keep_pos):\n",
    "    list_token_id = []\n",
    "    characters = json_data['characters']\n",
    "    for ch in characters:\n",
    "        if(ch['id'] == character_id):\n",
    "            if('speaking' in ch):\n",
    "                for speech in ch['speaking']:\n",
    "                    list_token_id.append(speech['i'])\n",
    "                \n",
    "    list_sent_id = getEquivalentSentId(df,list_token_id)\n",
    "    return getSentTextById(df,list_sent_id,window,keep_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAgentVerbs(json_data,character_id):\n",
    "    list_agent_verbs = []\n",
    "    characters = json_data['characters']\n",
    "    for ch in characters:\n",
    "        if(ch['id'] == character_id):\n",
    "            if('agent' in ch):\n",
    "                for agent in ch['agent']:\n",
    "                    list_agent_verbs.append(lemmatizeWord(agent['w'],'V'))\n",
    "    return list_agent_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getWindowText(df,character_id,window,keep_pos):\n",
    "    df_ch = df.groupby('characterId')['sentenceID'].apply(set).reset_index(name='sentence')\n",
    "    ch_sents = list(df_ch.loc[df_ch.characterId == character_id].sentence.reset_index(drop=True)[0])\n",
    "    return getSentTextById(df,ch_sents,window,keep_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getObjectsInPossession(json_data,character_id):\n",
    "    list_obj_poss_words = []\n",
    "    characters = json_data['characters']\n",
    "    for ch in characters:\n",
    "        if(ch['id'] == character_id):\n",
    "            if('poss' in ch):\n",
    "                for poss in ch['poss']:\n",
    "                    if(isObject(poss['w'])):\n",
    "                        list_obj_poss_words.append(lemmatizeWord(poss['w'],'N'))\n",
    "    return list_obj_poss_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLinks():\n",
    "    results = search_google.api.results(buildargs, cseargs)\n",
    "    return results.links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preProcessConcordText(concord_text):\n",
    "    ret = []\n",
    "    pos = nltk.pos_tag(concord_text)\n",
    "    for word,tag in pos:\n",
    "        if(tag in keep_pos):\n",
    "            ret.append(word.lower())\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def webScrapeData(topic):\n",
    "    book_web_scraped_data = []\n",
    "    cseargs['q'] = topic\n",
    "\n",
    "    for i in range(n_query_max_page):\n",
    "        cseargs['start'] = i + 1\n",
    "        links = getLinks()\n",
    "        for url in links:\n",
    "            book_web_scraped_data += queryLink(url)\n",
    "\n",
    "    return book_web_scraped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFeatureText(json_book_data,book_web_scraped_data,character_id,dict_id_char,book_name):\n",
    "    feature_text = []\n",
    "\n",
    "#   Using Novel Data    \n",
    "    feature_text += getSpeechText(json_book_data,character_id,window,keep_pos)\n",
    "    feature_text += getAgentVerbs(json_book_data,character_id)\n",
    "#     feature_text += getObjectsInPossession(json_book_data,character_id)\n",
    "#     feature_text += getWindowText(df,character_id,window,keep_pos)\n",
    "    character_name = dict_id_char[character_id]\n",
    "    \n",
    "#   Using Web Data\n",
    "    feature_text += getConcordance(character_name, book_web_scraped_data)\n",
    "    topic = character_name + '\\'s Character Analysis from ' + book_name\n",
    "    ch_web_data = webScrapeData(topic)\n",
    "    feature_text += getConcordance(character_name, ch_web_data)\n",
    "    \n",
    "    return feature_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSentimentScore(feature_text,df_neg_labelled,nnp_count):\n",
    "    if(feature_text is None):\n",
    "        return 0\n",
    "    \n",
    "    if(len(feature_text) == 0):\n",
    "        return 0\n",
    "    \n",
    "    pos_score = 0\n",
    "    neg_score = 0\n",
    "    list_neg_words = list(df_neg_labelled.list_neg_text)\n",
    "    hit_count = 0\n",
    "    \n",
    "    for word in feature_text:\n",
    "        if(word in list_neg_words):\n",
    "            hit_count += 1\n",
    "            score = df_neg_labelled.loc[list_neg_words.index(word)].neg_polarity\n",
    "            neg_score += score\n",
    "            \n",
    "    return (neg_score)/hit_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalizeSentiScore(senti_score,factor):\n",
    "    return senti_score * factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLabelFromSentiScore(senti_score,threshold):\n",
    "    if(senti_score > threshold):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isCharacterExist(ch_set,ch1,ch2):\n",
    "    if(ch1 in ch_set and ch2 in ch_set):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRowsWithMutipleCharacters(df):\n",
    "    df_ch_co_occur = df.loc[df.characterId != -1]\\\n",
    "    .groupby('sentenceID')['characterId']\\\n",
    "    .apply(set).reset_index(name='characters')\n",
    "\n",
    "    df_ch_co_occur['n_chars'] = df_ch_co_occur.characters.apply(len)\n",
    "    return df_ch_co_occur.loc[df_ch_co_occur.n_chars != 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRowsWithTwoCharacters(df_co_occur,ch1,ch2):\n",
    "    col_name = 'ch_' + str(ch1) + '_' + 'ch_' + str(ch2)\n",
    "    df_ch_co_occur[col_name] = df_ch_co_occur.apply\\\n",
    "    (lambda row: isCharacterExist(row['characters'],ch1,ch2), axis=1)\n",
    "    df_ch1_ch2 = df_ch_co_occur.loc[df_ch_co_occur[col_name] == True].reset_index(drop=True)\n",
    "    return df_ch1_ch2.drop(columns=[col_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idToName(ch_id,dict_id_char):\n",
    "    return dict_id_char[ch_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validation(df_val,df_close_chars,df_char_int,df_ch_rel):\n",
    "    data_character_list = list(df_val.Character)\n",
    "    model_character_list = list(df_close_chars.Character)\n",
    "    acc1 = retMatchAccuracy(data_character_list,model_character_list)\n",
    "    \n",
    "    df_merge = pd.merge(df_val, df_close_chars, on='Character')\n",
    "    zip1 = list(zip(df_merge.Close_Character_1,df_merge.Close_Character_2,df_merge.Close_Character_3))\n",
    "    zip2 = list(zip(df_merge.ch1_id,df_merge.ch2_id,df_merge.ch3_id))\n",
    "    acc2,n = retMatchAccuracyForTuple(zip1,zip2)\n",
    "    \n",
    "    df_merge = pd.merge(df_val, df_char_int, on='Character')\n",
    "    acc3 = exactListMatch(df_merge.Character_intergrity,df_merge.label_senti_score)\n",
    "    \n",
    "    acc = 0\n",
    "    for index,row in df_ch_rel.iterrows():\n",
    "        flag = 0\n",
    "        for i in range(n_close_chars):\n",
    "            col = 'Close_Character_' + str(i+1)\n",
    "            rel_col = 'Rel_Close_Character_' + str(i+1)\n",
    "            df_filter = df_val.loc[df_val.Character == row.ch1_id].loc[df_val[col] == row.ch2_id]\n",
    "            if(len(df_filter) != 0):\n",
    "                df_filter = df_filter.reset_index(drop=True)\n",
    "                true_label = df_filter.loc[0][rel_col]\n",
    "                pred_label = row.label_senti_score\n",
    "                if(true_label == pred_label):\n",
    "                    acc += 1\n",
    "                flag = 1\n",
    "                break\n",
    "    #     if(flag == 1):\n",
    "    #         print(true_label,pred_label,row.ch1_id,row.ch2_id)\n",
    "\n",
    "    acc4 = acc/n\n",
    "    \n",
    "    return acc1,acc2,acc3,acc4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Index CSV from Data Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>path</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hp_1</td>\n",
       "      <td>harry potter and the philosopher's stone</td>\n",
       "      <td>../data/harry_potter/stories/hp_1.txt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hp_2</td>\n",
       "      <td>harry potter and the chamber of secrets</td>\n",
       "      <td>../data/harry_potter/stories/hp_2.txt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hp_3</td>\n",
       "      <td>harry potter and the prisoner of azkaban</td>\n",
       "      <td>../data/harry_potter/stories/hp_3.txt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hp_4</td>\n",
       "      <td>harry potter and the goblet of fire</td>\n",
       "      <td>../data/harry_potter/stories/hp_4.txt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hp_5</td>\n",
       "      <td>harry potter and the order of the phoenix</td>\n",
       "      <td>../data/harry_potter/stories/hp_5.txt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                                      topic  \\\n",
       "0     hp_1   harry potter and the philosopher's stone   \n",
       "1     hp_2    harry potter and the chamber of secrets   \n",
       "2     hp_3   harry potter and the prisoner of azkaban   \n",
       "3     hp_4        harry potter and the goblet of fire   \n",
       "4     hp_5  harry potter and the order of the phoenix   \n",
       "\n",
       "                                    path validation  \n",
       "0  ../data/harry_potter/stories/hp_1.txt        NaN  \n",
       "1  ../data/harry_potter/stories/hp_2.txt        NaN  \n",
       "2  ../data/harry_potter/stories/hp_3.txt        NaN  \n",
       "3  ../data/harry_potter/stories/hp_4.txt        NaN  \n",
       "4  ../data/harry_potter/stories/hp_5.txt        NaN  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv(path_data_index)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Title of the Book and Webscrape Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.3 s, sys: 553 ms, total: 11.9 s\n",
      "Wall time: 36 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "377890"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_name = df_data.topic.loc[cur_story_index]\n",
    "book_web_scraped_data = %time webScrapeData(book_name)\n",
    "len(book_web_scraped_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Negative Labelled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>list_neg_text</th>\n",
       "      <th>neg_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abnormal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abolish</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abominable</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abominably</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abominate</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  list_neg_text  neg_polarity\n",
       "0      abnormal             1\n",
       "1       abolish             1\n",
       "2    abominable             3\n",
       "3    abominably             3\n",
       "4     abominate             3"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neg_labelled = pd.read_excel(path_bing_neg_score,index=False)\n",
    "df_neg_labelled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_neg_labelled.sample(n=200,replace=False).to_excel('for_kappa.xlsx',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Book-NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.7 ms, sys: 52 ms, total: 68.7 ms\n",
      "Wall time: 8min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../dependencies/book_nlp_output/hp_7/book.id.book',\n",
       " '../dependencies/book_nlp_output/hp_7.tokens')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonPath,tokensPath,retval = %time getBookNLPTokens(df_data.path[cur_story_index],\\\n",
    "                                              df_data.essay_id[cur_story_index],True)\n",
    "if(retval != 0):\n",
    "    print('Error running Book-NLP... Exiting Now\\nReturn Value:',retval)\n",
    "    sys.exit()\n",
    "    \n",
    "jsonPath,tokensPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Book-NLP Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.9 ms, sys: 31.9 ms, total: 55.8 ms\n",
      "Wall time: 84.6 ms\n",
      "CPU times: user 159 µs, sys: 36 µs, total: 195 µs\n",
      "Wall time: 201 µs\n"
     ]
    }
   ],
   "source": [
    "json_book_data = %time readJsonFile(jsonPath)\n",
    "dict_id_char = %time returnIDNameDict(json_book_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Book-NLP Token File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.38 s, sys: 539 ms, total: 5.92 s\n",
      "Wall time: 7.75 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraphId</th>\n",
       "      <th>sentenceID</th>\n",
       "      <th>tokenId</th>\n",
       "      <th>beginOffset</th>\n",
       "      <th>endOffset</th>\n",
       "      <th>whitespaceAfter</th>\n",
       "      <th>headTokenId</th>\n",
       "      <th>originalWord</th>\n",
       "      <th>normalizedWord</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>ner</th>\n",
       "      <th>deprel</th>\n",
       "      <th>inQuotation</th>\n",
       "      <th>characterId</th>\n",
       "      <th>supersense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>S</td>\n",
       "      <td>8</td>\n",
       "      <td>Chapter</td>\n",
       "      <td>Chapter</td>\n",
       "      <td>Chapter</td>\n",
       "      <td>NNP</td>\n",
       "      <td>MISC</td>\n",
       "      <td>nn</td>\n",
       "      <td>O</td>\n",
       "      <td>-1</td>\n",
       "      <td>B-noun.group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>One</td>\n",
       "      <td>One</td>\n",
       "      <td>one</td>\n",
       "      <td>CD</td>\n",
       "      <td>NUMBER</td>\n",
       "      <td>num</td>\n",
       "      <td>O</td>\n",
       "      <td>-1</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>S</td>\n",
       "      <td>6</td>\n",
       "      <td>The</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>MISC</td>\n",
       "      <td>det</td>\n",
       "      <td>O</td>\n",
       "      <td>-1</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>S</td>\n",
       "      <td>6</td>\n",
       "      <td>Dark</td>\n",
       "      <td>Dark</td>\n",
       "      <td>dark</td>\n",
       "      <td>JJ</td>\n",
       "      <td>MISC</td>\n",
       "      <td>amod</td>\n",
       "      <td>O</td>\n",
       "      <td>-1</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>S</td>\n",
       "      <td>6</td>\n",
       "      <td>Lord</td>\n",
       "      <td>Lord</td>\n",
       "      <td>Lord</td>\n",
       "      <td>NNP</td>\n",
       "      <td>MISC</td>\n",
       "      <td>nn</td>\n",
       "      <td>O</td>\n",
       "      <td>-1</td>\n",
       "      <td>B-noun.person</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paragraphId  sentenceID  tokenId  beginOffset  endOffset whitespaceAfter  \\\n",
       "0            0           0        0            0          7               S   \n",
       "1            0           0        1            8         11               S   \n",
       "2            0           0        2           12         15               S   \n",
       "3            0           0        3           16         20               S   \n",
       "4            0           0        4           21         25               S   \n",
       "\n",
       "   headTokenId originalWord normalizedWord    lemma  pos     ner deprel  \\\n",
       "0            8      Chapter        Chapter  Chapter  NNP    MISC     nn   \n",
       "1            0          One            One      one   CD  NUMBER    num   \n",
       "2            6          The            The      the   DT    MISC    det   \n",
       "3            6         Dark           Dark     dark   JJ    MISC   amod   \n",
       "4            6         Lord           Lord     Lord  NNP    MISC     nn   \n",
       "\n",
       "  inQuotation  characterId     supersense  \n",
       "0           O           -1   B-noun.group  \n",
       "1           O           -1              O  \n",
       "2           O           -1              O  \n",
       "3           O           -1              O  \n",
       "4           O           -1  B-noun.person  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = %time pd.read_csv(tokensPath,sep='\\t',engine='python',quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Compute Character Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.2 ms, sys: 5.98 ms, total: 51.2 ms\n",
      "Wall time: 60.4 ms\n",
      "CPU times: user 3min 4s, sys: 1.22 s, total: 3min 6s\n",
      "Wall time: 3min 39s\n"
     ]
    }
   ],
   "source": [
    "df_ch = %time getCharacterDF(df)\n",
    "character_distance_matrix = %time getCharacterDistanceMatrix(df_ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Top N Characters and Top M Close Characters for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.7 ms, sys: 6.32 ms, total: 53 ms\n",
      "Wall time: 108 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>ch1_id</th>\n",
       "      <th>ch2_id</th>\n",
       "      <th>ch3_id</th>\n",
       "      <th>character_name</th>\n",
       "      <th>ch1_name</th>\n",
       "      <th>ch2_name</th>\n",
       "      <th>ch3_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124</td>\n",
       "      <td>174</td>\n",
       "      <td>25</td>\n",
       "      <td>121</td>\n",
       "      <td>Ginny</td>\n",
       "      <td>Mrs. Weasley</td>\n",
       "      <td>Hogwarts</td>\n",
       "      <td>Hagrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>78</td>\n",
       "      <td>Kreacher</td>\n",
       "      <td>Sirius</td>\n",
       "      <td>Mundungus</td>\n",
       "      <td>Regulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80</td>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>Luna</td>\n",
       "      <td>Hogwarts</td>\n",
       "      <td>Fred</td>\n",
       "      <td>Fleur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121</td>\n",
       "      <td>174</td>\n",
       "      <td>124</td>\n",
       "      <td>119</td>\n",
       "      <td>Hagrid</td>\n",
       "      <td>Mrs. Weasley</td>\n",
       "      <td>Ginny</td>\n",
       "      <td>Voldemort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155</td>\n",
       "      <td>25</td>\n",
       "      <td>119</td>\n",
       "      <td>124</td>\n",
       "      <td>Snape</td>\n",
       "      <td>Hogwarts</td>\n",
       "      <td>Voldemort</td>\n",
       "      <td>Ginny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>119</td>\n",
       "      <td>53</td>\n",
       "      <td>95</td>\n",
       "      <td>170</td>\n",
       "      <td>Voldemort</td>\n",
       "      <td>Harry</td>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>Ron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>95</td>\n",
       "      <td>33</td>\n",
       "      <td>170</td>\n",
       "      <td>53</td>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>Hermione</td>\n",
       "      <td>Ron</td>\n",
       "      <td>Harry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>170</td>\n",
       "      <td>33</td>\n",
       "      <td>53</td>\n",
       "      <td>95</td>\n",
       "      <td>Ron</td>\n",
       "      <td>Hermione</td>\n",
       "      <td>Harry</td>\n",
       "      <td>Dumbledore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33</td>\n",
       "      <td>170</td>\n",
       "      <td>53</td>\n",
       "      <td>95</td>\n",
       "      <td>Hermione</td>\n",
       "      <td>Ron</td>\n",
       "      <td>Harry</td>\n",
       "      <td>Dumbledore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>53</td>\n",
       "      <td>33</td>\n",
       "      <td>170</td>\n",
       "      <td>95</td>\n",
       "      <td>Harry</td>\n",
       "      <td>Hermione</td>\n",
       "      <td>Ron</td>\n",
       "      <td>Dumbledore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Character  ch1_id  ch2_id  ch3_id character_name      ch1_name    ch2_name  \\\n",
       "0        124     174      25     121          Ginny  Mrs. Weasley    Hogwarts   \n",
       "1        112      27      59      78       Kreacher        Sirius   Mundungus   \n",
       "2         80      25      32     100           Luna      Hogwarts        Fred   \n",
       "3        121     174     124     119         Hagrid  Mrs. Weasley       Ginny   \n",
       "4        155      25     119     124          Snape      Hogwarts   Voldemort   \n",
       "5        119      53      95     170      Voldemort         Harry  Dumbledore   \n",
       "6         95      33     170      53     Dumbledore      Hermione         Ron   \n",
       "7        170      33      53      95            Ron      Hermione       Harry   \n",
       "8         33     170      53      95       Hermione           Ron       Harry   \n",
       "9         53      33     170      95          Harry      Hermione         Ron   \n",
       "\n",
       "     ch3_name  \n",
       "0      Hagrid  \n",
       "1     Regulus  \n",
       "2       Fleur  \n",
       "3   Voldemort  \n",
       "4       Ginny  \n",
       "5         Ron  \n",
       "6       Harry  \n",
       "7  Dumbledore  \n",
       "8  Dumbledore  \n",
       "9  Dumbledore  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_closest_characters = %time getTopNCloseCharacters(df,df_ch,json_book_data,\\\n",
    "                                                       character_distance_matrix,n_top_chars,n_close_chars)\n",
    "# transformDictIDToName(dict_closest_characters,dict_id_char,False)\n",
    "df_close_chars = pd.DataFrame.from_dict(dict_closest_characters)\\\n",
    ".transpose()\\\n",
    ".reset_index()\\\n",
    ".rename(index=str, columns={\"index\": \"Character\"})\\\n",
    ".rename(index=int, columns={0: 'ch1_id', 1: 'ch2_id', 2: 'ch3_id'})\n",
    "\n",
    "df_close_chars['character_name'] = df_close_chars.apply(lambda row: idToName(row['Character'], dict_id_char), axis=1)\n",
    "df_close_chars['ch1_name'] = df_close_chars.apply(lambda row: idToName(row['ch1_id'], dict_id_char), axis=1)\n",
    "df_close_chars['ch2_name'] = df_close_chars.apply(lambda row: idToName(row['ch2_id'], dict_id_char), axis=1)\n",
    "df_close_chars['ch3_name'] = df_close_chars.apply(lambda row: idToName(row['ch3_id'], dict_id_char), axis=1)\n",
    "\n",
    "df_close_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Integrity Analysis on the Top N Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.4 s, sys: 865 ms, total: 21.3 s\n",
      "Wall time: 56.1 s\n",
      "CPU times: user 12.1 s, sys: 266 ms, total: 12.4 s\n",
      "Wall time: 38 s\n",
      "CPU times: user 12.4 s, sys: 236 ms, total: 12.6 s\n",
      "Wall time: 38.4 s\n",
      "CPU times: user 20 s, sys: 753 ms, total: 20.7 s\n",
      "Wall time: 45.8 s\n",
      "CPU times: user 10.2 s, sys: 629 ms, total: 10.8 s\n",
      "Wall time: 27.7 s\n",
      "CPU times: user 14.9 s, sys: 839 ms, total: 15.8 s\n",
      "Wall time: 42.2 s\n",
      "CPU times: user 15.3 s, sys: 1.13 s, total: 16.4 s\n",
      "Wall time: 44.1 s\n",
      "CPU times: user 11.3 s, sys: 673 ms, total: 12 s\n",
      "Wall time: 51.6 s\n",
      "CPU times: user 16.1 s, sys: 1.28 s, total: 17.4 s\n",
      "Wall time: 1min 3s\n",
      "CPU times: user 42.4 s, sys: 3.28 s, total: 45.7 s\n",
      "Wall time: 1min 21s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>senti_score</th>\n",
       "      <th>ch1_name</th>\n",
       "      <th>norm_senti_score</th>\n",
       "      <th>label_senti_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124.0</td>\n",
       "      <td>1.276836</td>\n",
       "      <td>Ginny</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112.0</td>\n",
       "      <td>1.782123</td>\n",
       "      <td>Kreacher</td>\n",
       "      <td>0.120731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80.0</td>\n",
       "      <td>1.370968</td>\n",
       "      <td>Luna</td>\n",
       "      <td>0.092877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121.0</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>Hagrid</td>\n",
       "      <td>0.088916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155.0</td>\n",
       "      <td>1.578059</td>\n",
       "      <td>Snape</td>\n",
       "      <td>0.106906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>119.0</td>\n",
       "      <td>1.705411</td>\n",
       "      <td>Voldemort</td>\n",
       "      <td>0.115534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>95.0</td>\n",
       "      <td>1.448845</td>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>0.098153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>170.0</td>\n",
       "      <td>1.495238</td>\n",
       "      <td>Ron</td>\n",
       "      <td>0.101296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33.0</td>\n",
       "      <td>1.332767</td>\n",
       "      <td>Hermione</td>\n",
       "      <td>0.090289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>53.0</td>\n",
       "      <td>1.458388</td>\n",
       "      <td>Harry</td>\n",
       "      <td>0.098799</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Character  senti_score    ch1_name  norm_senti_score  label_senti_score\n",
       "0      124.0     1.276836       Ginny          0.086500                  1\n",
       "1      112.0     1.782123    Kreacher          0.120731                  0\n",
       "2       80.0     1.370968        Luna          0.092877                  1\n",
       "3      121.0     1.312500      Hagrid          0.088916                  1\n",
       "4      155.0     1.578059       Snape          0.106906                  0\n",
       "5      119.0     1.705411   Voldemort          0.115534                  0\n",
       "6       95.0     1.448845  Dumbledore          0.098153                  1\n",
       "7      170.0     1.495238         Ron          0.101296                  0\n",
       "8       33.0     1.332767    Hermione          0.090289                  1\n",
       "9       53.0     1.458388       Harry          0.098799                  1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_senti_score = {}\n",
    "for ch,close_ch in dict_closest_characters.items():\n",
    "    feature_text = %time getFeatureText(json_book_data,book_web_scraped_data,ch,dict_id_char,book_name)\n",
    "    nnp_count = getNNPCount(json_book_data,ch)\n",
    "    ch_senti_score[ch] = getSentimentScore(feature_text,df_neg_labelled,nnp_count)\n",
    "    \n",
    "df_char_int = pd.DataFrame(columns=['Character', 'senti_score'])\n",
    "for key,val in ch_senti_score.items():\n",
    "    df_char_int.loc[len(df_char_int)] = [key,val]\n",
    "df_char_int['ch1_name'] = df_char_int.apply(lambda row: idToName(row['Character'], dict_id_char), axis=1)\n",
    "df_char_int['norm_senti_score'] = df_char_int.apply(lambda row: normalizeSentiScore(row['senti_score'], 1.0/sum(df_char_int.senti_score)), axis=1)\n",
    "df_char_int['label_senti_score'] = df_char_int.apply(lambda row: getLabelFromSentiScore(row['norm_senti_score'], 1.0/len(df_char_int.senti_score)), axis=1)\n",
    "df_char_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Nature of Character Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ch1_id</th>\n",
       "      <th>ch2_id</th>\n",
       "      <th>senti_score</th>\n",
       "      <th>ch1_name</th>\n",
       "      <th>ch2_name</th>\n",
       "      <th>norm_senti_score</th>\n",
       "      <th>label_senti_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.023280</td>\n",
       "      <td>Ginny</td>\n",
       "      <td>Mrs. Weasley</td>\n",
       "      <td>0.034336</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.105933</td>\n",
       "      <td>Ginny</td>\n",
       "      <td>Hogwarts</td>\n",
       "      <td>0.156244</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.042140</td>\n",
       "      <td>Ginny</td>\n",
       "      <td>Hagrid</td>\n",
       "      <td>0.062153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>112.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-0.299583</td>\n",
       "      <td>Kreacher</td>\n",
       "      <td>Sirius</td>\n",
       "      <td>-0.441863</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>-0.163771</td>\n",
       "      <td>Kreacher</td>\n",
       "      <td>Mundungus</td>\n",
       "      <td>-0.241551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>112.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.367400</td>\n",
       "      <td>Kreacher</td>\n",
       "      <td>Regulus</td>\n",
       "      <td>0.541888</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>80.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.678000</td>\n",
       "      <td>Luna</td>\n",
       "      <td>Hogwarts</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.401900</td>\n",
       "      <td>Luna</td>\n",
       "      <td>Fred</td>\n",
       "      <td>0.592773</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>80.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.049388</td>\n",
       "      <td>Luna</td>\n",
       "      <td>Fleur</td>\n",
       "      <td>0.072843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>121.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>-0.212967</td>\n",
       "      <td>Hagrid</td>\n",
       "      <td>Mrs. Weasley</td>\n",
       "      <td>-0.314110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>121.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.042140</td>\n",
       "      <td>Hagrid</td>\n",
       "      <td>Ginny</td>\n",
       "      <td>0.062153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>121.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>-0.143614</td>\n",
       "      <td>Hagrid</td>\n",
       "      <td>Voldemort</td>\n",
       "      <td>-0.211820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>155.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-0.000900</td>\n",
       "      <td>Snape</td>\n",
       "      <td>Hogwarts</td>\n",
       "      <td>-0.001327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>155.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.003595</td>\n",
       "      <td>Snape</td>\n",
       "      <td>Voldemort</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>155.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.210833</td>\n",
       "      <td>Snape</td>\n",
       "      <td>Ginny</td>\n",
       "      <td>0.310964</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>119.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-0.125627</td>\n",
       "      <td>Voldemort</td>\n",
       "      <td>Harry</td>\n",
       "      <td>-0.185291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>119.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-0.254272</td>\n",
       "      <td>Voldemort</td>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>-0.375032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>119.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>-0.172462</td>\n",
       "      <td>Voldemort</td>\n",
       "      <td>Ron</td>\n",
       "      <td>-0.254368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>95.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.037009</td>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>Hermione</td>\n",
       "      <td>0.054585</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>95.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.084262</td>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>Ron</td>\n",
       "      <td>0.124280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>95.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-0.028519</td>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>Harry</td>\n",
       "      <td>-0.042064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>170.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-0.038892</td>\n",
       "      <td>Ron</td>\n",
       "      <td>Hermione</td>\n",
       "      <td>-0.057364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>170.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-0.045848</td>\n",
       "      <td>Ron</td>\n",
       "      <td>Harry</td>\n",
       "      <td>-0.067623</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>170.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.084262</td>\n",
       "      <td>Ron</td>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>0.124280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>33.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>-0.038892</td>\n",
       "      <td>Hermione</td>\n",
       "      <td>Ron</td>\n",
       "      <td>-0.057364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>33.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-0.046957</td>\n",
       "      <td>Hermione</td>\n",
       "      <td>Harry</td>\n",
       "      <td>-0.069258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>33.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.037009</td>\n",
       "      <td>Hermione</td>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>0.054585</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>53.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-0.046957</td>\n",
       "      <td>Harry</td>\n",
       "      <td>Hermione</td>\n",
       "      <td>-0.069258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>-0.045848</td>\n",
       "      <td>Harry</td>\n",
       "      <td>Ron</td>\n",
       "      <td>-0.067623</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>53.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-0.028519</td>\n",
       "      <td>Harry</td>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>-0.042064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ch1_id  ch2_id  senti_score    ch1_name      ch2_name  norm_senti_score  \\\n",
       "0    124.0   174.0     0.023280       Ginny  Mrs. Weasley          0.034336   \n",
       "1    124.0    25.0     0.105933       Ginny      Hogwarts          0.156244   \n",
       "2    124.0   121.0     0.042140       Ginny        Hagrid          0.062153   \n",
       "3    112.0    27.0    -0.299583    Kreacher        Sirius         -0.441863   \n",
       "4    112.0    59.0    -0.163771    Kreacher     Mundungus         -0.241551   \n",
       "5    112.0    78.0     0.367400    Kreacher       Regulus          0.541888   \n",
       "6     80.0    25.0     0.678000        Luna      Hogwarts          1.000000   \n",
       "7     80.0    32.0     0.401900        Luna          Fred          0.592773   \n",
       "8     80.0   100.0     0.049388        Luna         Fleur          0.072843   \n",
       "9    121.0   174.0    -0.212967      Hagrid  Mrs. Weasley         -0.314110   \n",
       "10   121.0   124.0     0.042140      Hagrid         Ginny          0.062153   \n",
       "11   121.0   119.0    -0.143614      Hagrid     Voldemort         -0.211820   \n",
       "12   155.0    25.0    -0.000900       Snape      Hogwarts         -0.001327   \n",
       "13   155.0   119.0     0.003595       Snape     Voldemort          0.005303   \n",
       "14   155.0   124.0     0.210833       Snape         Ginny          0.310964   \n",
       "15   119.0    53.0    -0.125627   Voldemort         Harry         -0.185291   \n",
       "16   119.0    95.0    -0.254272   Voldemort    Dumbledore         -0.375032   \n",
       "17   119.0   170.0    -0.172462   Voldemort           Ron         -0.254368   \n",
       "18    95.0    33.0     0.037009  Dumbledore      Hermione          0.054585   \n",
       "19    95.0   170.0     0.084262  Dumbledore           Ron          0.124280   \n",
       "20    95.0    53.0    -0.028519  Dumbledore         Harry         -0.042064   \n",
       "21   170.0    33.0    -0.038892         Ron      Hermione         -0.057364   \n",
       "22   170.0    53.0    -0.045848         Ron         Harry         -0.067623   \n",
       "23   170.0    95.0     0.084262         Ron    Dumbledore          0.124280   \n",
       "24    33.0   170.0    -0.038892    Hermione           Ron         -0.057364   \n",
       "25    33.0    53.0    -0.046957    Hermione         Harry         -0.069258   \n",
       "26    33.0    95.0     0.037009    Hermione    Dumbledore          0.054585   \n",
       "27    53.0    33.0    -0.046957       Harry      Hermione         -0.069258   \n",
       "28    53.0   170.0    -0.045848       Harry           Ron         -0.067623   \n",
       "29    53.0    95.0    -0.028519       Harry    Dumbledore         -0.042064   \n",
       "\n",
       "    label_senti_score  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   0  \n",
       "4                   0  \n",
       "5                   1  \n",
       "6                   1  \n",
       "7                   1  \n",
       "8                   1  \n",
       "9                   0  \n",
       "10                  1  \n",
       "11                  0  \n",
       "12                  1  \n",
       "13                  1  \n",
       "14                  1  \n",
       "15                  0  \n",
       "16                  0  \n",
       "17                  0  \n",
       "18                  1  \n",
       "19                  1  \n",
       "20                  1  \n",
       "21                  1  \n",
       "22                  1  \n",
       "23                  1  \n",
       "24                  1  \n",
       "25                  1  \n",
       "26                  1  \n",
       "27                  1  \n",
       "28                  1  \n",
       "29                  1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ch_co_occur = getRowsWithMutipleCharacters(df)\n",
    "df_ch_rel = pd.DataFrame(columns=['ch1_id', 'ch2_id', 'senti_score'])\n",
    "\n",
    "for ch1,close_ch in dict_closest_characters.items():\n",
    "    for ch2 in close_ch:\n",
    "        list_senti_score = []\n",
    "        df_ch1_ch2 = getRowsWithTwoCharacters(df_ch_co_occur,ch1,ch2)\n",
    "        list_sent_id = getUnqColVals(df_ch1_ch2,'sentenceID')\n",
    "        for sent_id in list_sent_id:\n",
    "            sentence = getSentTextById(df=df,\\\n",
    "                            list_sent_id=[sent_id],\\\n",
    "                            isStr=True,\\\n",
    "                            keep_pos=None,\\\n",
    "                            is_lemmatize=False,\\\n",
    "                            is_remove_stop_words=False)\n",
    "            \n",
    "            nltk_sent_analysis = nltk_senti_analyzer.polarity_scores(sentence)\n",
    "            list_senti_score.append(nltk_sent_analysis.get('compound'))\n",
    "            \n",
    "        df_ch_rel.loc[len(df_ch_rel)] = [ch1,ch2,np.mean(list_senti_score)]\n",
    "        \n",
    "df_ch_rel['ch1_name'] = df_ch_rel.apply(lambda row: idToName(row['ch1_id'], dict_id_char), axis=1)\n",
    "df_ch_rel['ch2_name'] = df_ch_rel.apply(lambda row: idToName(row['ch2_id'], dict_id_char), axis=1)\n",
    "df_ch_rel['norm_senti_score'] = [(float(i)/max(df_ch_rel.senti_score)) for i in df_ch_rel.senti_score]\n",
    "threshold = np.mean(df_ch_rel['norm_senti_score']) - (np.std(df_ch_rel['norm_senti_score'])/2)\n",
    "df_ch_rel['label_senti_score'] = df_ch_rel.norm_senti_score.apply(lambda x: 0 if x < threshold else 1)\n",
    "df_ch_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Identifying Top N Important Characters: 1.0\n",
      "Accuracy of Identifying Top k Close Relationships for Every Character: 0.5757575757575757\n",
      "Accuracy of Classsifying the Integrity of Every Character: 0.9090909090909091\n",
      "Accuracy of Classsifying the Nature of Every Relationship: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "#Validation\n",
    "path_valid = df_data.loc[cur_story_index].validation\n",
    "if(path_valid is not np.nan):\n",
    "    df_val = pd.read_excel(path_valid)\n",
    "    ac1,ac2,ac3,ac4 = validation(df_val,df_close_chars,df_char_int,df_ch_rel)\n",
    "    print('Accuracy of Identifying Top N Important Characters:',ac1)\n",
    "    print('Accuracy of Identifying Top k Close Relationships for Every Character:',ac2)\n",
    "    print('Accuracy of Classsifying the Integrity of Every Character:',ac3)\n",
    "    print('Accuracy of Classsifying the Nature of Every Relationship:',ac4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_close_chars.to_excel(path_output_ch,index=False)\n",
    "df_char_int.to_excel(path_output_int,index=False)\n",
    "df_ch_rel.to_excel(path_output_ch_rel,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
