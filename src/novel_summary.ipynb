{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novel Summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kksaikrishna/anaconda3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "import nltk\n",
    "import sys\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "import search_google.api\n",
    "import urllib.request as requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path Conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_data_index = '../data/non_fiction_novels/index.csv'\n",
    "path_book_nlp_out = '../../dependencies/book_nlp_output/'\n",
    "path_bing_neg_score = '../dependencies/bing_sentiment_lexicons/negative-words-labelled.xlsx'\n",
    "path_output_ch = '../output/top_close_characters.xlsx'\n",
    "path_output_int = '../output/character_integrity.xlsx'\n",
    "path_output_ch_rel = '../output/character_relationship.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "nltk_senti_analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Config Params DO NOT CHANGE\n",
    "cur_story_index = 10 # 10 for pp, 6 for hp\n",
    "n_close_chars = 3 \n",
    "n_top_chars = 10\n",
    "keep_pos = ['JJ','JJS','JJR','RR','RBR','RBS','VB','VBD','VBG','VBN','VBP','VBZ']\n",
    "window = 0\n",
    "n_query_max_page = 5\n",
    "n_query_per_page = 10\n",
    "concord_left_margin = 5\n",
    "concord_right_margin = 5\n",
    "n_concord = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buildargs = {\n",
    "  'serviceName': 'customsearch',\n",
    "  'version': 'v1',\n",
    "  'developerKey': 'AIzaSyBAEWHb_bLgqpmY_NY50ykZDz9JI_ZH1GQ'\n",
    "}\n",
    "\n",
    "cseargs = {\n",
    "  'q': '',\n",
    "  'cx': '009620542372427651480:rc6g5pqmltw',\n",
    "  'num': n_query_per_page,\n",
    "  'start':1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readJsonFile(jsonPath):\n",
    "    with open(jsonPath) as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeKeysFromDict(dict_vals,keepList):\n",
    "    dict_ret = {}\n",
    "    for k in keepList:\n",
    "        if(k in dict_vals):\n",
    "            dict_ret[k] = dict_vals[k]\n",
    "    return dict_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isObject(word):\n",
    "    wn_word = word.lower() + '.n.01'\n",
    "    try:\n",
    "        wn_lemma = wn.synset(wn_word)\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    l_hyper = str(list(wn_lemma.closure(lambda s: s.hypernyms())))\n",
    "    if('object.n.01' in l_hyper and 'living_thing.n.01' not in l_hyper):\n",
    "        return True\n",
    "    else:\n",
    "        return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getWordnetPos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def queryLink(url):\n",
    "    try:\n",
    "        html = requests.urlopen(url).read().decode('utf8')\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "    return nltk.word_tokenize(BeautifulSoup(html,'lxml').get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatizeWord(word,pos_tag):\n",
    "    pos_tag = getWordnetPos(pos_tag)\n",
    "    if(pos_tag != ''):\n",
    "        return lemmatizer.lemmatize(word,pos_tag)\n",
    "    else:\n",
    "        return lemmatizer.lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getConcordance(target_word, main_text, left_margin = concord_left_margin,\\\n",
    "                   right_margin = concord_right_margin,\\\n",
    "                   n_concord = n_concord,is_pre_process=True):     \n",
    "    if(n_concord == -1):\n",
    "        n_concord = np.inf\n",
    "\n",
    "    concord_text = []\n",
    "    cur_iter = 0\n",
    "    while(cur_iter < n_concord):\n",
    "        if(target_word in main_text):\n",
    "            index = main_text.index(target_word)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        concord_text += main_text[index - left_margin : index + right_margin + 1]\n",
    "\n",
    "        if(index+1 < len(main_text)):\n",
    "            main_text = main_text[index+1:]\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        cur_iter += 1\n",
    "    if(is_pre_process):\n",
    "        concord_text = preProcessConcordText(concord_text)\n",
    "    return concord_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getUnqColVals(df,col_name):\n",
    "    return list(set(df[col_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retMatchAccuracy(list1,list2,div_by_2=True):\n",
    "    n = len(set(list1).intersection(set(list2)))\n",
    "    if(div_by_2):\n",
    "        return n/len(list2)\n",
    "    return n/list(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retMatchAccuracyForTuple(list1,list2):\n",
    "    if(len(list1) != len(list2)):\n",
    "        return 0\n",
    "    \n",
    "    if(len(list1) == 0):\n",
    "        return 0\n",
    "    \n",
    "    n = len(list1)\n",
    "    acc = 0\n",
    "    hit_count = 0\n",
    "    for tup1,tup2 in zip(list1,list2):\n",
    "        if(len(tup1) != len(tup2)):\n",
    "            return 0\n",
    "        \n",
    "        acc += len(set(tup1).intersection(set(tup2)))/len(tup1)\n",
    "        hit_count += len(set(tup1).intersection(set(tup2)))\n",
    "        \n",
    "    return acc/n,hit_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exactListMatch(list1,list2):\n",
    "    if(len(list1) != len(list2)):\n",
    "        return 0\n",
    "    \n",
    "    if(len(list1) == 0):\n",
    "        return 0\n",
    "    \n",
    "    acc = len([i for i, j in zip(list1, list2) if i == j])\n",
    "    \n",
    "    return acc/len(list1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initializeCharacterMatrix(df):\n",
    "    character_distance_matrix = np.empty((len(df), len(df)))\n",
    "    character_distance_matrix[:] = np.inf\n",
    "    return character_distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createBookNLPCommand(path,story_id,isForce,isReturnPath=False):\n",
    "    jsonPath = path_book_nlp_out + story_id\n",
    "    tokensPath = path_book_nlp_out + story_id + '.tokens'\n",
    "    \n",
    "    command = './runjava novels/BookNLP -doc ../'\n",
    "    command += path\n",
    "    command += ' -p '\n",
    "    command += jsonPath\n",
    "    command += ' -tok '\n",
    "    command += tokensPath\n",
    "    if(isForce):\n",
    "        command += ' -f'\n",
    "    \n",
    "    if(isReturnPath):\n",
    "        return command, jsonPath +'/book.id.book', tokensPath\n",
    "    else:\n",
    "        return command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBookNLPTokens(path,story_id,isForce=False):\n",
    "    command,jsonPath,tokensPath = createBookNLPCommand(path,story_id,isForce,True)\n",
    "    p = subprocess.Popen(command, shell=True, cwd='../resources/book-nlp-master')\n",
    "    retval = p.wait()\n",
    "    return jsonPath[3:],tokensPath[3:],retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCharacterIDFromIndex(indices,df,lookup_col):\n",
    "    ret = []\n",
    "    for i in indices:\n",
    "        ret.append(df[lookup_col][i])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCharacterDF(df,n_top_chars=None):\n",
    "    df = df.loc[df.characterId != -1]\n",
    "    df_ch = df.groupby('characterId')['tokenId'].apply(list).reset_index(name='tokens')\n",
    "    df_ch.tokens = df_ch.tokens.apply(sorted)\n",
    "    df_ch['tok_len'] = df_ch.tokens.apply(len)\n",
    "    \n",
    "    if(n_top_chars is not None):\n",
    "        df_ch = df_ch.sort_values(by='tok_len',ascending=False).reset_index(drop=True)[:n_top_chars]\n",
    "        df_ch = df_ch.sort_values(by='tok_len').reset_index(drop=True)\n",
    "    else:\n",
    "        df_ch = df_ch.sort_values(by='tok_len',ascending=False).reset_index(drop=True)\n",
    "        \n",
    "    return df_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCharacterDistanceMatrix(df_ch):\n",
    "    character_distance_matrix = initializeCharacterMatrix(df_ch)\n",
    "\n",
    "    for index1,token1 in enumerate(df_ch.tokens):\n",
    "        for index2,token2 in enumerate(df_ch.tokens):\n",
    "            if(index1 == index2):\n",
    "                continue\n",
    "            elif(index1 < index2):\n",
    "                iter_token = token1\n",
    "                cons_token = token2\n",
    "            else:\n",
    "                iter_token = token2\n",
    "                cons_token = token1\n",
    "\n",
    "            dist = 0\n",
    "            for tok in iter_token:\n",
    "                dist += np.min(abs(np.array(cons_token)-tok))\n",
    "            character_distance_matrix[index1][index2] = (dist/(len(iter_token)))\n",
    "            \n",
    "    return character_distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNNPCount(json_data,character_id):\n",
    "    characters = json_data['characters']\n",
    "    for ch in characters:\n",
    "        if(ch['id'] == character_id):\n",
    "            if('NNPcount' in ch):\n",
    "                return ch['NNPcount']\n",
    "            else:\n",
    "                return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTopNCharacters(json_data,list_character_id,n):\n",
    "    dict_nnp_count = {}\n",
    "    for ch in list_character_id:\n",
    "        dict_nnp_count[ch] = getNNPCount(json_data,ch)\n",
    "    return sorted(list_character_id, key=dict_nnp_count.get)[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTopNCloseCharacters(df,df_ch,json_book_data,character_distance_matrix,n_top_chars=10,n_close_chars=3):\n",
    "    closest_characters = {}\n",
    "    for index,character_distance_vector in enumerate(character_distance_matrix):\n",
    "        min_distance_characters = getCharacterIDFromIndex(np.argsort(character_distance_vector)[:n_close_chars],\\\n",
    "                                                          df_ch,'characterId')\n",
    "        i_ch = getCharacterIDFromIndex([index],df_ch,'characterId')\n",
    "        closest_characters[i_ch[0]] = min_distance_characters\n",
    "        \n",
    "    list_character_id = set(df.characterId)\n",
    "    list_character_id.remove(-1)\n",
    "    list_character_id = list(list_character_id)\n",
    "    \n",
    "    top_n_ch = getTopNCharacters(json_book_data,list_character_id,n_top_chars)\n",
    "    \n",
    "    return removeKeysFromDict(closest_characters,top_n_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def returnIDNameDict(json_data):\n",
    "    dict_char = {}\n",
    "    characters = json_data['characters']\n",
    "    for ch in characters:\n",
    "        dict_char[ch['id']] = ch['names'][0]['n']\n",
    "    return dict_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transformDictIDToName(dict_characters,dict_id_char,isOnlyKey=True):\n",
    "    dict_ret = {}\n",
    "    for key,val in dict_characters.items():\n",
    "        if(isOnlyKey):\n",
    "            dict_ret[dict_id_char[key]]  = val\n",
    "        else:\n",
    "            cur = []\n",
    "            for ch in val:\n",
    "                 cur.append(dict_id_char[ch])\n",
    "            dict_ret[dict_id_char[key]] = cur\n",
    "            \n",
    "    return dict_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getEquivalentSentId(df,list_token_id):\n",
    "    sentId = set()\n",
    "    for token_id in list_token_id:\n",
    "        sentId.add(df.loc[df.tokenId == token_id].sentenceID.reset_index(drop=True)[0])\n",
    "    return list(sentId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSentTextById(df,list_sent_id,window=0,keep_pos=None,is_remove_stop_words=True,is_lemmatize=True,isStr = False):\n",
    "    window_sent_id = []\n",
    "    for sent_id in list_sent_id:\n",
    "        window_sent_id += list(range(sent_id-window,sent_id+window+1))\n",
    "        \n",
    "    df_sent_window = df.loc[df.sentenceID.isin(window_sent_id)]\n",
    "    \n",
    "    if(keep_pos is not None and len(df_sent_window) != 0):\n",
    "        df_sent_window = df_sent_window.loc[df_sent_window.pos.isin(keep_pos)]\n",
    "    \n",
    "    if(is_remove_stop_words and len(df_sent_window) != 0):\n",
    "        df_sent_window = df_sent_window.loc[~df_sent_window.lemma.isin(stop_words)]\n",
    "        \n",
    "    if(is_lemmatize and len(df_sent_window) != 0):\n",
    "        df_sent_window.lemma = df_sent_window.apply(lambda row: lemmatizeWord(row['lemma'], row['pos']), axis=1)\n",
    "    \n",
    "    if(isStr):\n",
    "        return ' '.join(list(df_sent_window.lemma))\n",
    "    \n",
    "    return list(df_sent_window.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSpeechText(json_data,character_id,window,keep_pos):\n",
    "    list_token_id = []\n",
    "    characters = json_data['characters']\n",
    "    for ch in characters:\n",
    "        if(ch['id'] == character_id):\n",
    "            if('speaking' in ch):\n",
    "                for speech in ch['speaking']:\n",
    "                    list_token_id.append(speech['i'])\n",
    "                \n",
    "    list_sent_id = getEquivalentSentId(df,list_token_id)\n",
    "    return getSentTextById(df,list_sent_id,window,keep_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAgentVerbs(json_data,character_id):\n",
    "    list_agent_verbs = []\n",
    "    characters = json_data['characters']\n",
    "    for ch in characters:\n",
    "        if(ch['id'] == character_id):\n",
    "            if('agent' in ch):\n",
    "                for agent in ch['agent']:\n",
    "                    list_agent_verbs.append(lemmatizeWord(agent['w'],'V'))\n",
    "    return list_agent_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getWindowText(df,character_id,window,keep_pos):\n",
    "    df_ch = df.groupby('characterId')['sentenceID'].apply(set).reset_index(name='sentence')\n",
    "    ch_sents = list(df_ch.loc[df_ch.characterId == character_id].sentence.reset_index(drop=True)[0])\n",
    "    return getSentTextById(df,ch_sents,window,keep_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getObjectsInPossession(json_data,character_id):\n",
    "    list_obj_poss_words = []\n",
    "    characters = json_data['characters']\n",
    "    for ch in characters:\n",
    "        if(ch['id'] == character_id):\n",
    "            if('poss' in ch):\n",
    "                for poss in ch['poss']:\n",
    "                    if(isObject(poss['w'])):\n",
    "                        list_obj_poss_words.append(lemmatizeWord(poss['w'],'N'))\n",
    "    return list_obj_poss_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLinks():\n",
    "    results = search_google.api.results(buildargs, cseargs)\n",
    "    return results.links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preProcessConcordText(concord_text):\n",
    "    ret = []\n",
    "    pos = nltk.pos_tag(concord_text)\n",
    "    for word,tag in pos:\n",
    "        if(tag in keep_pos):\n",
    "            ret.append(word.lower())\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def webScrapeData(topic):\n",
    "    book_web_scraped_data = []\n",
    "    cseargs['q'] = topic\n",
    "\n",
    "    for i in range(n_query_max_page):\n",
    "        cseargs['start'] = i + 1\n",
    "        links = getLinks()\n",
    "        for url in links:\n",
    "            book_web_scraped_data += queryLink(url)\n",
    "\n",
    "    return book_web_scraped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFeatureText(json_book_data,book_web_scraped_data,character_id,dict_id_char,book_name):\n",
    "    feature_text = []\n",
    "\n",
    "#   Using Novel Data    \n",
    "    feature_text += getSpeechText(json_book_data,character_id,window,keep_pos)\n",
    "    feature_text += getAgentVerbs(json_book_data,character_id)\n",
    "    feature_text += getObjectsInPossession(json_book_data,character_id)\n",
    "    feature_text += getWindowText(df,character_id,window,keep_pos)\n",
    "    character_name = dict_id_char[character_id]\n",
    "    \n",
    "#   Using Web Data\n",
    "    feature_text += getConcordance(character_name, book_web_scraped_data)\n",
    "    topic = character_name + '\\'s Character Analysis from ' + book_name\n",
    "    ch_web_data = webScrapeData(topic)\n",
    "    feature_text += getConcordance(character_name, ch_web_data)\n",
    "    \n",
    "    return feature_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSentimentScore(feature_text,df_neg_labelled,nnp_count):\n",
    "    if(feature_text is None):\n",
    "        return 0\n",
    "    \n",
    "    if(len(feature_text) == 0):\n",
    "        return 0\n",
    "    \n",
    "    pos_score = 0\n",
    "    neg_score = 0\n",
    "    list_neg_words = list(df_neg_labelled.list_neg_text)\n",
    "    hit_count = 0\n",
    "    \n",
    "    for word in feature_text:\n",
    "        if(word in list_neg_words):\n",
    "            hit_count += 1\n",
    "            score = df_neg_labelled.loc[list_neg_words.index(word)].neg_polarity\n",
    "            neg_score += score\n",
    "            \n",
    "    return (neg_score)/hit_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalizeSentiScore(senti_score,factor):\n",
    "    return senti_score * factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLabelFromSentiScore(senti_score,threshold):\n",
    "    if(senti_score > threshold):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isCharacterExist(ch_set,ch1,ch2):\n",
    "    if(ch1 in ch_set and ch2 in ch_set):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRowsWithMutipleCharacters(df):\n",
    "    df_ch_co_occur = df.loc[df.characterId != -1]\\\n",
    "    .groupby('sentenceID')['characterId']\\\n",
    "    .apply(set).reset_index(name='characters')\n",
    "\n",
    "    df_ch_co_occur['n_chars'] = df_ch_co_occur.characters.apply(len)\n",
    "    return df_ch_co_occur.loc[df_ch_co_occur.n_chars != 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRowsWithTwoCharacters(df_co_occur,ch1,ch2):\n",
    "    col_name = 'ch_' + str(ch1) + '_' + 'ch_' + str(ch2)\n",
    "    df_ch_co_occur[col_name] = df_ch_co_occur.apply\\\n",
    "    (lambda row: isCharacterExist(row['characters'],ch1,ch2), axis=1)\n",
    "    df_ch1_ch2 = df_ch_co_occur.loc[df_ch_co_occur[col_name] == True].reset_index(drop=True)\n",
    "    return df_ch1_ch2.drop(columns=[col_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idToName(ch_id,dict_id_char):\n",
    "    return dict_id_char[ch_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validation(df_val,df_close_chars,df_char_int,df_ch_rel):\n",
    "    data_character_list = list(df_val.Character)\n",
    "    model_character_list = list(df_close_chars.Character)\n",
    "    acc1 = retMatchAccuracy(data_character_list,model_character_list)\n",
    "    \n",
    "    df_merge = pd.merge(df_val, df_close_chars, on='Character')\n",
    "    zip1 = list(zip(df_merge.Close_Character_1,df_merge.Close_Character_2,df_merge.Close_Character_3))\n",
    "    zip2 = list(zip(df_merge.ch1_id,df_merge.ch2_id,df_merge.ch3_id))\n",
    "    acc2,n = retMatchAccuracyForTuple(zip1,zip2)\n",
    "    \n",
    "    df_merge = pd.merge(df_val, df_char_int, on='Character')\n",
    "    acc3 = exactListMatch(df_merge.Character_intergrity,df_merge.label_senti_score)\n",
    "    \n",
    "    acc = 0\n",
    "    for index,row in df_ch_rel.iterrows():\n",
    "        flag = 0\n",
    "        for i in range(n_close_chars):\n",
    "            col = 'Close_Character_' + str(i+1)\n",
    "            rel_col = 'Rel_Close_Character_' + str(i+1)\n",
    "            df_filter = df_val.loc[df_val.Character == row.ch1_id].loc[df_val[col] == row.ch2_id]\n",
    "            if(len(df_filter) != 0):\n",
    "                df_filter = df_filter.reset_index(drop=True)\n",
    "                true_label = df_filter.loc[0][rel_col]\n",
    "                pred_label = row.label_senti_score\n",
    "                if(true_label == pred_label):\n",
    "                    acc += 1\n",
    "                flag = 1\n",
    "                break\n",
    "    #     if(flag == 1):\n",
    "    #         print(true_label,pred_label,row.ch1_id,row.ch2_id)\n",
    "\n",
    "    acc4 = acc/n\n",
    "    \n",
    "    return acc1,acc2,acc3,acc4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Index CSV from Data Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>path</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>st_1</td>\n",
       "      <td>Sense and Sensibility</td>\n",
       "      <td>../data/non_fiction_novels/stories/st_1.txt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>st_2</td>\n",
       "      <td>Wuthering Heights</td>\n",
       "      <td>../data/non_fiction_novels/stories/st_2.txt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>st_3</td>\n",
       "      <td>Christmas Carol</td>\n",
       "      <td>../data/non_fiction_novels/stories/st_3.txt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>st_4</td>\n",
       "      <td>Oliver Twist</td>\n",
       "      <td>../data/non_fiction_novels/stories/st_4.txt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>st_5</td>\n",
       "      <td>King Solomon's Mines</td>\n",
       "      <td>../data/non_fiction_novels/stories/st_5.txt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id                  topic  \\\n",
       "0     st_1  Sense and Sensibility   \n",
       "1     st_2      Wuthering Heights   \n",
       "2     st_3        Christmas Carol   \n",
       "3     st_4           Oliver Twist   \n",
       "4     st_5   King Solomon's Mines   \n",
       "\n",
       "                                          path validation  \n",
       "0  ../data/non_fiction_novels/stories/st_1.txt        NaN  \n",
       "1  ../data/non_fiction_novels/stories/st_2.txt        NaN  \n",
       "2  ../data/non_fiction_novels/stories/st_3.txt        NaN  \n",
       "3  ../data/non_fiction_novels/stories/st_4.txt        NaN  \n",
       "4  ../data/non_fiction_novels/stories/st_5.txt        NaN  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv(path_data_index)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Title of the Book and Webscrape Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.83 s, sys: 160 ms, total: 2.99 s\n",
      "Wall time: 7.34 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68093"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_name = df_data.topic.loc[cur_story_index]\n",
    "book_web_scraped_data = %time webScrapeData(book_name)\n",
    "len(book_web_scraped_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Negative Labelled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>list_neg_text</th>\n",
       "      <th>neg_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abnormal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abolish</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abominable</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abominably</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abominate</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  list_neg_text  neg_polarity\n",
       "0      abnormal             1\n",
       "1       abolish             1\n",
       "2    abominable             3\n",
       "3    abominably             3\n",
       "4     abominate             3"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neg_labelled = pd.read_excel(path_bing_neg_score,index=False)\n",
    "df_neg_labelled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_neg_labelled.sample(n=200,replace=False).to_excel('for_kappa.xlsx',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Book-NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.26 ms, sys: 30.5 ms, total: 39.7 ms\n",
      "Wall time: 3min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../dependencies/book_nlp_output/st_11/book.id.book',\n",
       " '../dependencies/book_nlp_output/st_11.tokens')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonPath,tokensPath,retval = %time getBookNLPTokens(df_data.path[cur_story_index],\\\n",
    "                                              df_data.essay_id[cur_story_index],True)\n",
    "if(retval != 0):\n",
    "    print('Error running Book-NLP... Exiting Now\\nReturn Value:',retval)\n",
    "    sys.exit()\n",
    "    \n",
    "jsonPath,tokensPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Book-NLP Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 ms, sys: 29.9 ms, total: 42 ms\n",
      "Wall time: 171 ms\n",
      "CPU times: user 71 µs, sys: 28 µs, total: 99 µs\n",
      "Wall time: 104 µs\n"
     ]
    }
   ],
   "source": [
    "json_book_data = %time readJsonFile(jsonPath)\n",
    "dict_id_char = %time returnIDNameDict(json_book_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Book-NLP Token File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.31 s, sys: 718 ms, total: 3.03 s\n",
      "Wall time: 3.54 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraphId</th>\n",
       "      <th>sentenceID</th>\n",
       "      <th>tokenId</th>\n",
       "      <th>beginOffset</th>\n",
       "      <th>endOffset</th>\n",
       "      <th>whitespaceAfter</th>\n",
       "      <th>headTokenId</th>\n",
       "      <th>originalWord</th>\n",
       "      <th>normalizedWord</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>ner</th>\n",
       "      <th>deprel</th>\n",
       "      <th>inQuotation</th>\n",
       "      <th>characterId</th>\n",
       "      <th>supersense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>S</td>\n",
       "      <td>-1</td>\n",
       "      <td>Chapter</td>\n",
       "      <td>Chapter</td>\n",
       "      <td>chapter</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>-1</td>\n",
       "      <td>B-noun.communication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>NNN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CD</td>\n",
       "      <td>NUMBER</td>\n",
       "      <td>num</td>\n",
       "      <td>O</td>\n",
       "      <td>-1</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>S</td>\n",
       "      <td>5</td>\n",
       "      <td>It</td>\n",
       "      <td>It</td>\n",
       "      <td>it</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>O</td>\n",
       "      <td>-1</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>S</td>\n",
       "      <td>5</td>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>O</td>\n",
       "      <td>cop</td>\n",
       "      <td>O</td>\n",
       "      <td>-1</td>\n",
       "      <td>B-verb.stative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>S</td>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "      <td>det</td>\n",
       "      <td>O</td>\n",
       "      <td>-1</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paragraphId  sentenceID  tokenId  beginOffset  endOffset whitespaceAfter  \\\n",
       "0            0           0        0            0          7               S   \n",
       "1            0           0        1            8          9             NNN   \n",
       "2            1           0        2           12         14               S   \n",
       "3            1           0        3           15         17               S   \n",
       "4            1           0        4           18         19               S   \n",
       "\n",
       "   headTokenId originalWord normalizedWord    lemma  pos     ner deprel  \\\n",
       "0           -1      Chapter        Chapter  chapter   NN       O    NaN   \n",
       "1            0            1              1        1   CD  NUMBER    num   \n",
       "2            5           It             It       it  PRP       O  nsubj   \n",
       "3            5           is             is       be  VBZ       O    cop   \n",
       "4            5            a              a        a   DT       O    det   \n",
       "\n",
       "  inQuotation  characterId            supersense  \n",
       "0           O           -1  B-noun.communication  \n",
       "1           O           -1                     O  \n",
       "2           O           -1                     O  \n",
       "3           O           -1        B-verb.stative  \n",
       "4           O           -1                     O  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = %time pd.read_csv(tokensPath,sep='\\t',engine='python',quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Compute Character Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.7 ms, sys: 5.76 ms, total: 41.5 ms\n",
      "Wall time: 61.4 ms\n",
      "CPU times: user 32.5 s, sys: 502 ms, total: 33 s\n",
      "Wall time: 33.5 s\n"
     ]
    }
   ],
   "source": [
    "df_ch = %time getCharacterDF(df)\n",
    "character_distance_matrix = %time getCharacterDistanceMatrix(df_ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Top N Characters and Top M Close Characters for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.6 ms, sys: 1.68 ms, total: 22.3 ms\n",
      "Wall time: 21.6 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>ch1_id</th>\n",
       "      <th>ch2_id</th>\n",
       "      <th>ch3_id</th>\n",
       "      <th>character_name</th>\n",
       "      <th>ch1_name</th>\n",
       "      <th>ch2_name</th>\n",
       "      <th>ch3_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>Lizzy</td>\n",
       "      <td>Mrs. Gardiner</td>\n",
       "      <td>Kitty</td>\n",
       "      <td>Mrs. Bennet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>Lady Catherine</td>\n",
       "      <td>Mr. Collins</td>\n",
       "      <td>Rosings</td>\n",
       "      <td>Mrs. Bennet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "      <td>Mr. Collins</td>\n",
       "      <td>Lady Catherine</td>\n",
       "      <td>Lydia</td>\n",
       "      <td>Mrs. Bennet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>47</td>\n",
       "      <td>59</td>\n",
       "      <td>16</td>\n",
       "      <td>Mrs. Bennet</td>\n",
       "      <td>Lydia</td>\n",
       "      <td>Mr. Bennet</td>\n",
       "      <td>Jane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "      <td>69</td>\n",
       "      <td>Lydia</td>\n",
       "      <td>Mrs. Bennet</td>\n",
       "      <td>Mr. Bennet</td>\n",
       "      <td>Wickham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>69</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>Wickham</td>\n",
       "      <td>Lydia</td>\n",
       "      <td>Mrs. Bennet</td>\n",
       "      <td>Miss Darcy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>Mr. Bingley</td>\n",
       "      <td>Mr. Darcy</td>\n",
       "      <td>Jane</td>\n",
       "      <td>Mrs. Bennet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>Jane</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>Mr. Darcy</td>\n",
       "      <td>Mr. Bingley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>67</td>\n",
       "      <td>Mr. Darcy</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>Jane</td>\n",
       "      <td>Mr. Bingley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>67</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>Mr. Darcy</td>\n",
       "      <td>Jane</td>\n",
       "      <td>Mr. Bingley</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Character  ch1_id  ch2_id  ch3_id  character_name        ch1_name  \\\n",
       "0         41      38      39      50           Lizzy   Mrs. Gardiner   \n",
       "1          2      13      40      50  Lady Catherine     Mr. Collins   \n",
       "2         13       2      47      50     Mr. Collins  Lady Catherine   \n",
       "3         50      47      59      16     Mrs. Bennet           Lydia   \n",
       "4         47      50      59      69           Lydia     Mrs. Bennet   \n",
       "5         69      47      50      12         Wickham           Lydia   \n",
       "6         67       1      16      50     Mr. Bingley       Mr. Darcy   \n",
       "7         16      48       1      67            Jane       Elizabeth   \n",
       "8          1      48      16      67       Mr. Darcy       Elizabeth   \n",
       "9         48       1      16      67       Elizabeth       Mr. Darcy   \n",
       "\n",
       "      ch2_name     ch3_name  \n",
       "0        Kitty  Mrs. Bennet  \n",
       "1      Rosings  Mrs. Bennet  \n",
       "2        Lydia  Mrs. Bennet  \n",
       "3   Mr. Bennet         Jane  \n",
       "4   Mr. Bennet      Wickham  \n",
       "5  Mrs. Bennet   Miss Darcy  \n",
       "6         Jane  Mrs. Bennet  \n",
       "7    Mr. Darcy  Mr. Bingley  \n",
       "8         Jane  Mr. Bingley  \n",
       "9         Jane  Mr. Bingley  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_closest_characters = %time getTopNCloseCharacters(df,df_ch,json_book_data,\\\n",
    "                                                       character_distance_matrix,n_top_chars,n_close_chars)\n",
    "# transformDictIDToName(dict_closest_characters,dict_id_char,False)\n",
    "df_close_chars = pd.DataFrame.from_dict(dict_closest_characters)\\\n",
    ".transpose()\\\n",
    ".reset_index()\\\n",
    ".rename(index=str, columns={\"index\": \"Character\"})\\\n",
    ".rename(index=int, columns={0: 'ch1_id', 1: 'ch2_id', 2: 'ch3_id'})\n",
    "\n",
    "df_close_chars['character_name'] = df_close_chars.apply(lambda row: idToName(row['Character'], dict_id_char), axis=1)\n",
    "df_close_chars['ch1_name'] = df_close_chars.apply(lambda row: idToName(row['ch1_id'], dict_id_char), axis=1)\n",
    "df_close_chars['ch2_name'] = df_close_chars.apply(lambda row: idToName(row['ch2_id'], dict_id_char), axis=1)\n",
    "df_close_chars['ch3_name'] = df_close_chars.apply(lambda row: idToName(row['ch3_id'], dict_id_char), axis=1)\n",
    "\n",
    "df_close_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Integrity Analysis on the Top N Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 s, sys: 369 ms, total: 11.6 s\n",
      "Wall time: 28 s\n",
      "CPU times: user 6.2 s, sys: 166 ms, total: 6.36 s\n",
      "Wall time: 17.5 s\n",
      "CPU times: user 7.4 s, sys: 177 ms, total: 7.57 s\n",
      "Wall time: 19.5 s\n",
      "CPU times: user 7.7 s, sys: 218 ms, total: 7.92 s\n",
      "Wall time: 23 s\n",
      "CPU times: user 9.33 s, sys: 346 ms, total: 9.67 s\n",
      "Wall time: 23.1 s\n",
      "CPU times: user 8.9 s, sys: 383 ms, total: 9.29 s\n",
      "Wall time: 20.7 s\n",
      "CPU times: user 7.32 s, sys: 225 ms, total: 7.54 s\n",
      "Wall time: 18.6 s\n",
      "CPU times: user 11.3 s, sys: 437 ms, total: 11.7 s\n",
      "Wall time: 25.5 s\n",
      "CPU times: user 9.08 s, sys: 222 ms, total: 9.3 s\n",
      "Wall time: 22 s\n",
      "CPU times: user 15.3 s, sys: 723 ms, total: 16.1 s\n",
      "Wall time: 31 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>senti_score</th>\n",
       "      <th>ch1_name</th>\n",
       "      <th>norm_senti_score</th>\n",
       "      <th>label_senti_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>1.208955</td>\n",
       "      <td>Lizzy</td>\n",
       "      <td>0.090268</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>Lady Catherine</td>\n",
       "      <td>0.100800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>Mr. Collins</td>\n",
       "      <td>0.099555</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1.347305</td>\n",
       "      <td>Mrs. Bennet</td>\n",
       "      <td>0.100598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1.385113</td>\n",
       "      <td>Lydia</td>\n",
       "      <td>0.103421</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>69.0</td>\n",
       "      <td>1.445205</td>\n",
       "      <td>Wickham</td>\n",
       "      <td>0.107908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.344828</td>\n",
       "      <td>Mr. Bingley</td>\n",
       "      <td>0.100413</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.302115</td>\n",
       "      <td>Jane</td>\n",
       "      <td>0.097224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.361266</td>\n",
       "      <td>Mr. Darcy</td>\n",
       "      <td>0.101641</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48.0</td>\n",
       "      <td>1.314799</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>0.098171</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Character  senti_score        ch1_name  norm_senti_score  label_senti_score\n",
       "0       41.0     1.208955           Lizzy          0.090268                  1\n",
       "1        2.0     1.350000  Lady Catherine          0.100800                  0\n",
       "2       13.0     1.333333     Mr. Collins          0.099555                  1\n",
       "3       50.0     1.347305     Mrs. Bennet          0.100598                  0\n",
       "4       47.0     1.385113           Lydia          0.103421                  0\n",
       "5       69.0     1.445205         Wickham          0.107908                  0\n",
       "6       67.0     1.344828     Mr. Bingley          0.100413                  0\n",
       "7       16.0     1.302115            Jane          0.097224                  1\n",
       "8        1.0     1.361266       Mr. Darcy          0.101641                  0\n",
       "9       48.0     1.314799       Elizabeth          0.098171                  1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_senti_score = {}\n",
    "for ch,close_ch in dict_closest_characters.items():\n",
    "    feature_text = %time getFeatureText(json_book_data,book_web_scraped_data,ch,dict_id_char,book_name)\n",
    "    nnp_count = getNNPCount(json_book_data,ch)\n",
    "    ch_senti_score[ch] = getSentimentScore(feature_text,df_neg_labelled,nnp_count)\n",
    "    \n",
    "df_char_int = pd.DataFrame(columns=['Character', 'senti_score'])\n",
    "for key,val in ch_senti_score.items():\n",
    "    df_char_int.loc[len(df_char_int)] = [key,val]\n",
    "df_char_int['ch1_name'] = df_char_int.apply(lambda row: idToName(row['Character'], dict_id_char), axis=1)\n",
    "df_char_int['norm_senti_score'] = df_char_int.apply(lambda row: normalizeSentiScore(row['senti_score'], 1.0/sum(df_char_int.senti_score)), axis=1)\n",
    "df_char_int['label_senti_score'] = df_char_int.apply(lambda row: getLabelFromSentiScore(row['norm_senti_score'], 1.0/len(df_char_int.senti_score)), axis=1)\n",
    "df_char_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Nature of Character Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ch1_id</th>\n",
       "      <th>ch2_id</th>\n",
       "      <th>senti_score</th>\n",
       "      <th>ch1_name</th>\n",
       "      <th>ch2_name</th>\n",
       "      <th>norm_senti_score</th>\n",
       "      <th>label_senti_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Lizzy</td>\n",
       "      <td>Mrs. Gardiner</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>-0.050926</td>\n",
       "      <td>Lizzy</td>\n",
       "      <td>Kitty</td>\n",
       "      <td>-0.071475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-0.041049</td>\n",
       "      <td>Lizzy</td>\n",
       "      <td>Mrs. Bennet</td>\n",
       "      <td>-0.057613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.186041</td>\n",
       "      <td>Lady Catherine</td>\n",
       "      <td>Mr. Collins</td>\n",
       "      <td>0.261110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.012674</td>\n",
       "      <td>Lady Catherine</td>\n",
       "      <td>Rosings</td>\n",
       "      <td>0.017788</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>Lady Catherine</td>\n",
       "      <td>Mrs. Bennet</td>\n",
       "      <td>0.497076</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.186041</td>\n",
       "      <td>Mr. Collins</td>\n",
       "      <td>Lady Catherine</td>\n",
       "      <td>0.261110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.086146</td>\n",
       "      <td>Mr. Collins</td>\n",
       "      <td>Lydia</td>\n",
       "      <td>0.120906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.165385</td>\n",
       "      <td>Mr. Collins</td>\n",
       "      <td>Mrs. Bennet</td>\n",
       "      <td>0.232120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.133282</td>\n",
       "      <td>Mrs. Bennet</td>\n",
       "      <td>Lydia</td>\n",
       "      <td>0.187062</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.167429</td>\n",
       "      <td>Mrs. Bennet</td>\n",
       "      <td>Mr. Bennet</td>\n",
       "      <td>0.234987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.017496</td>\n",
       "      <td>Mrs. Bennet</td>\n",
       "      <td>Jane</td>\n",
       "      <td>0.024556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>47.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.133282</td>\n",
       "      <td>Lydia</td>\n",
       "      <td>Mrs. Bennet</td>\n",
       "      <td>0.187062</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>47.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.046319</td>\n",
       "      <td>Lydia</td>\n",
       "      <td>Mr. Bennet</td>\n",
       "      <td>0.065010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>47.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.054361</td>\n",
       "      <td>Lydia</td>\n",
       "      <td>Wickham</td>\n",
       "      <td>0.076296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>69.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.054361</td>\n",
       "      <td>Wickham</td>\n",
       "      <td>Lydia</td>\n",
       "      <td>0.076296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>69.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.062183</td>\n",
       "      <td>Wickham</td>\n",
       "      <td>Mrs. Bennet</td>\n",
       "      <td>0.087274</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>69.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>Wickham</td>\n",
       "      <td>Miss Darcy</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.192969</td>\n",
       "      <td>Mr. Bingley</td>\n",
       "      <td>Mr. Darcy</td>\n",
       "      <td>0.270834</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>67.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.104278</td>\n",
       "      <td>Mr. Bingley</td>\n",
       "      <td>Jane</td>\n",
       "      <td>0.146355</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>67.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.131509</td>\n",
       "      <td>Mr. Bingley</td>\n",
       "      <td>Mrs. Bennet</td>\n",
       "      <td>0.184574</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>16.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.115602</td>\n",
       "      <td>Jane</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>0.162249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>Jane</td>\n",
       "      <td>Mr. Darcy</td>\n",
       "      <td>0.072346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>16.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.104278</td>\n",
       "      <td>Jane</td>\n",
       "      <td>Mr. Bingley</td>\n",
       "      <td>0.146355</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.094535</td>\n",
       "      <td>Mr. Darcy</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>0.132681</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>Mr. Darcy</td>\n",
       "      <td>Jane</td>\n",
       "      <td>0.072346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.192969</td>\n",
       "      <td>Mr. Darcy</td>\n",
       "      <td>Mr. Bingley</td>\n",
       "      <td>0.270834</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.094535</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>Mr. Darcy</td>\n",
       "      <td>0.132681</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>48.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.115602</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>Jane</td>\n",
       "      <td>0.162249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>48.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.124367</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>Mr. Bingley</td>\n",
       "      <td>0.174550</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ch1_id  ch2_id  senti_score        ch1_name        ch2_name  \\\n",
       "0     41.0    38.0     0.250000           Lizzy   Mrs. Gardiner   \n",
       "1     41.0    39.0    -0.050926           Lizzy           Kitty   \n",
       "2     41.0    50.0    -0.041049           Lizzy     Mrs. Bennet   \n",
       "3      2.0    13.0     0.186041  Lady Catherine     Mr. Collins   \n",
       "4      2.0    40.0     0.012674  Lady Catherine         Rosings   \n",
       "5      2.0    50.0     0.354167  Lady Catherine     Mrs. Bennet   \n",
       "6     13.0     2.0     0.186041     Mr. Collins  Lady Catherine   \n",
       "7     13.0    47.0     0.086146     Mr. Collins           Lydia   \n",
       "8     13.0    50.0     0.165385     Mr. Collins     Mrs. Bennet   \n",
       "9     50.0    47.0     0.133282     Mrs. Bennet           Lydia   \n",
       "10    50.0    59.0     0.167429     Mrs. Bennet      Mr. Bennet   \n",
       "11    50.0    16.0     0.017496     Mrs. Bennet            Jane   \n",
       "12    47.0    50.0     0.133282           Lydia     Mrs. Bennet   \n",
       "13    47.0    59.0     0.046319           Lydia      Mr. Bennet   \n",
       "14    47.0    69.0     0.054361           Lydia         Wickham   \n",
       "15    69.0    47.0     0.054361         Wickham           Lydia   \n",
       "16    69.0    50.0     0.062183         Wickham     Mrs. Bennet   \n",
       "17    69.0    12.0     0.712500         Wickham      Miss Darcy   \n",
       "18    67.0     1.0     0.192969     Mr. Bingley       Mr. Darcy   \n",
       "19    67.0    16.0     0.104278     Mr. Bingley            Jane   \n",
       "20    67.0    50.0     0.131509     Mr. Bingley     Mrs. Bennet   \n",
       "21    16.0    48.0     0.115602            Jane       Elizabeth   \n",
       "22    16.0     1.0     0.051546            Jane       Mr. Darcy   \n",
       "23    16.0    67.0     0.104278            Jane     Mr. Bingley   \n",
       "24     1.0    48.0     0.094535       Mr. Darcy       Elizabeth   \n",
       "25     1.0    16.0     0.051546       Mr. Darcy            Jane   \n",
       "26     1.0    67.0     0.192969       Mr. Darcy     Mr. Bingley   \n",
       "27    48.0     1.0     0.094535       Elizabeth       Mr. Darcy   \n",
       "28    48.0    16.0     0.115602       Elizabeth            Jane   \n",
       "29    48.0    67.0     0.124367       Elizabeth     Mr. Bingley   \n",
       "\n",
       "    norm_senti_score  label_senti_score  \n",
       "0           0.350877                  1  \n",
       "1          -0.071475                  0  \n",
       "2          -0.057613                  0  \n",
       "3           0.261110                  1  \n",
       "4           0.017788                  0  \n",
       "5           0.497076                  1  \n",
       "6           0.261110                  1  \n",
       "7           0.120906                  1  \n",
       "8           0.232120                  1  \n",
       "9           0.187062                  1  \n",
       "10          0.234987                  1  \n",
       "11          0.024556                  0  \n",
       "12          0.187062                  1  \n",
       "13          0.065010                  0  \n",
       "14          0.076296                  0  \n",
       "15          0.076296                  0  \n",
       "16          0.087274                  0  \n",
       "17          1.000000                  1  \n",
       "18          0.270834                  1  \n",
       "19          0.146355                  1  \n",
       "20          0.184574                  1  \n",
       "21          0.162249                  1  \n",
       "22          0.072346                  0  \n",
       "23          0.146355                  1  \n",
       "24          0.132681                  1  \n",
       "25          0.072346                  0  \n",
       "26          0.270834                  1  \n",
       "27          0.132681                  1  \n",
       "28          0.162249                  1  \n",
       "29          0.174550                  1  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ch_co_occur = getRowsWithMutipleCharacters(df)\n",
    "df_ch_rel = pd.DataFrame(columns=['ch1_id', 'ch2_id', 'senti_score'])\n",
    "\n",
    "for ch1,close_ch in dict_closest_characters.items():\n",
    "    for ch2 in close_ch:\n",
    "        list_senti_score = []\n",
    "        df_ch1_ch2 = getRowsWithTwoCharacters(df_ch_co_occur,ch1,ch2)\n",
    "        list_sent_id = getUnqColVals(df_ch1_ch2,'sentenceID')\n",
    "        for sent_id in list_sent_id:\n",
    "            sentence = getSentTextById(df=df,\\\n",
    "                            list_sent_id=[sent_id],\\\n",
    "                            isStr=True,\\\n",
    "                            keep_pos=None,\\\n",
    "                            is_lemmatize=False,\\\n",
    "                            is_remove_stop_words=False)\n",
    "            \n",
    "#             nltk_sent_analysis = nltk_senti_analyzer.polarity_scores(sentence)\n",
    "#             list_senti_score.append(nltk_sent_analysis.get('compound'))\n",
    "            list_senti_score.append(TextBlob(sentence).sentiment.polarity)\n",
    "            \n",
    "        df_ch_rel.loc[len(df_ch_rel)] = [ch1,ch2,np.mean(list_senti_score)]\n",
    "        \n",
    "df_ch_rel['ch1_name'] = df_ch_rel.apply(lambda row: idToName(row['ch1_id'], dict_id_char), axis=1)\n",
    "df_ch_rel['ch2_name'] = df_ch_rel.apply(lambda row: idToName(row['ch2_id'], dict_id_char), axis=1)\n",
    "df_ch_rel['norm_senti_score'] = [(float(i)/max(df_ch_rel.senti_score)) for i in df_ch_rel.senti_score]\n",
    "threshold = np.mean(df_ch_rel['norm_senti_score']) - (np.std(df_ch_rel['norm_senti_score'])/2)\n",
    "df_ch_rel['label_senti_score'] = df_ch_rel.norm_senti_score.apply(lambda x: 0 if x < threshold else 1)\n",
    "df_ch_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Identifying Top N Important Characters: 0.5\n",
      "Accuracy of Identifying Top k Close Relationships for Every Character: 0.26666666666666666\n",
      "Accuracy of Classsifying the Integrity of Every Character: 0.8\n",
      "Accuracy of Classsifying the Nature of Every Relationship: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Validation\n",
    "path_valid = df_data.loc[cur_story_index].validation\n",
    "if(path_valid is not np.nan):\n",
    "    df_val = pd.read_excel(path_valid)\n",
    "    ac1,ac2,ac3,ac4 = validation(df_val,df_close_chars,df_char_int,df_ch_rel)\n",
    "    print('Accuracy of Identifying Top N Important Characters:',ac1)\n",
    "    print('Accuracy of Identifying Top k Close Relationships for Every Character:',ac2)\n",
    "    print('Accuracy of Classsifying the Integrity of Every Character:',ac3)\n",
    "    print('Accuracy of Classsifying the Nature of Every Relationship:',ac4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_close_chars.to_excel(path_output_ch,index=False)\n",
    "df_char_int.to_excel(path_output_int,index=False)\n",
    "df_ch_rel.to_excel(path_output_ch_rel,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
